{"cells": [{"cell_type": "code", "execution_count": 2, "id": "a958abcb-e7a2-4340-8cfb-83b1ad00a33f", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "[2025-08-04T15:04:01.825755] INFO - Config file read from GCS\n[2025-08-04T15:04:03.130861] INFO - Moved landing/hospital-a/encounters/encounters_04082025.json to landing/hospital-a/archive/encounters/2025/08/04/encounters_04082025.json\n[2025-08-04T15:04:04.166542] INFO - Latest watermark for encounters: 2025-08-04 14:47:13.904624+00:00\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "[2025-08-04T15:04:07.034496] SUCCESS - Extracted 0 rows from encounters\n[2025-08-04T15:04:07.190495] SUCCESS - Data written to GCS at landing/hospital-a/encounters/encounters_04082025.json\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "[2025-08-04T15:04:25.396609] SUCCESS - Audit logged for encounters\n[2025-08-04T15:04:26.616070] INFO - Latest watermark for patients: 2025-08-04 14:47:31.606692+00:00\n[2025-08-04T15:04:27.341033] SUCCESS - Extracted 0 rows from patients\n[2025-08-04T15:04:27.496143] SUCCESS - Data written to GCS at landing/hospital-a/patients/patients_04082025.json\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "[2025-08-04T15:04:39.803861] SUCCESS - Audit logged for patients\n[2025-08-04T15:04:41.057745] INFO - Latest watermark for transactions: 2025-08-04 14:40:40.429157+00:00\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "[2025-08-04T15:04:42.777374] SUCCESS - Extracted 0 rows from transactions\n[2025-08-04T15:04:42.942221] SUCCESS - Data written to GCS at landing/hospital-a/transactions/transactions_04082025.json\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "[2025-08-04T15:04:49.489982] SUCCESS - Audit logged for transactions\n[2025-08-04T15:04:49.513605] INFO - Latest watermark for providers: None\n[2025-08-04T15:04:50.344639] SUCCESS - Extracted 26 rows from providers\n[2025-08-04T15:04:51.025068] SUCCESS - Data written to GCS at landing/hospital-a/providers/providers_04082025.json\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "[2025-08-04T15:04:59.714515] SUCCESS - Audit logged for providers\n[2025-08-04T15:04:59.741160] INFO - Latest watermark for departments: None\n[2025-08-04T15:05:00.389652] SUCCESS - Extracted 21 rows from departments\n[2025-08-04T15:05:00.967031] SUCCESS - Data written to GCS at landing/hospital-a/departments/departments_04082025.json\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "[2025-08-04T15:05:07.460345] SUCCESS - Audit logged for departments\n\u2705 Logs saved to GCS: gs://healthcare-bucket-192/temp/pipeline_logs/pipeline_log_20250804150507.json\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "\u2705 Logs written to BigQuery\n"}], "source": "from google.cloud import storage, bigquery\nfrom pyspark.sql import SparkSession\nimport datetime\nimport json\n\n# Initialize Spark Session (if not already)\ntry:\n    spark\nexcept NameError:\n    spark = SparkSession.builder \\\n        .appName(\"MyApp\") \\\n        .getOrCreate()\n\n# GCS and BigQuery Clients\nstorage_client = storage.Client()\nbq_client = bigquery.Client()\n\n# Configuration\nGCS_BUCKET = \"healthcare-bucket-192\"\nHOSPITAL_NAME = \"hospital-a\"\nLANDING_PATH = f\"gs://{GCS_BUCKET}/landing/{HOSPITAL_NAME}/\"\nARCHIVE_PATH = f\"gs://{GCS_BUCKET}/landing/{HOSPITAL_NAME}/archive/\"\nCONFIG_FILE_PATH = f\"gs://{GCS_BUCKET}/configs/load_config.csv\"\n\nBQ_PROJECT = \"gcpdataengineering-467713\"\nBQ_AUDIT_TABLE = f\"{BQ_PROJECT}.temp_dataset.audit_log\"\nBQ_LOG_TABLE = f\"{BQ_PROJECT}.temp_dataset.pipeline_logs\"\n\nMYSQL_CONFIG = {\n    \"url\": \"jdbc:mysql://34.9.188.225:3306/hospital_a_db?useSSL=false&allowPublicKeyRetrieval=true\",\n    \"driver\": \"com.mysql.cj.jdbc.Driver\",\n    \"user\": \"myuser\",\n    \"password\": \"Dishu_192\"\n}\n\n# Logging\nlog_entries = []\n\ndef log_event(event_type, message, table=None):\n    entry = {\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"event_type\": event_type,\n        \"message\": message,\n        \"table\": table\n    }\n    log_entries.append(entry)\n    print(f\"[{entry['timestamp']}] {event_type} - {message}\")\n\ndef save_logs_to_gcs():\n    log_file = f\"temp/pipeline_logs/pipeline_log_{datetime.datetime.now().strftime('%Y%m%d%H%M%S')}.json\"\n    blob = storage_client.bucket(GCS_BUCKET).blob(log_file)\n    blob.upload_from_string(json.dumps(log_entries, indent=4), content_type=\"application/json\")\n    print(f\"\u2705 Logs saved to GCS: gs://{GCS_BUCKET}/{log_file}\")\n\ndef save_logs_to_bigquery():\n    if log_entries:\n        log_df = spark.createDataFrame(log_entries)\n        log_df.write.format(\"bigquery\") \\\n            .option(\"table\", BQ_LOG_TABLE) \\\n            .option(\"temporaryGcsBucket\", GCS_BUCKET) \\\n            .mode(\"append\") \\\n            .save()\n        print(\"\u2705 Logs written to BigQuery\")\n\ndef move_existing_files_to_archive(table):\n    blobs = storage_client.bucket(GCS_BUCKET).list_blobs(prefix=f\"landing/{HOSPITAL_NAME}/{table}/\")\n    for blob in blobs:\n        if blob.name.endswith(\".json\"):\n            file = blob.name\n            date_part = file.split(\"_\")[-1].split(\".\")[0]\n            year, month, day = date_part[-4:], date_part[2:4], date_part[:2]\n            archive_blob_name = f\"landing/{HOSPITAL_NAME}/archive/{table}/{year}/{month}/{day}/{file.split('/')[-1]}\"\n            dest_blob = storage_client.bucket(GCS_BUCKET).blob(archive_blob_name)\n            dest_blob.rewrite(blob)\n            blob.delete()\n            log_event(\"INFO\", f\"Moved {file} to {archive_blob_name}\", table=table)\n\ndef get_latest_watermark(table_name):\n    query = f\"\"\"\n        SELECT MAX(load_timestamp) AS latest_timestamp\n        FROM `{BQ_AUDIT_TABLE}`\n        WHERE tablename = '{table_name}' AND data_source = \"hospital_a_db\"\n    \"\"\"\n    try:\n        result = bq_client.query(query).result()\n        for row in result:\n            return row.latest_timestamp or \"1900-01-01 00:00:00\"\n    except Exception as e:\n        log_event(\"ERROR\", f\"Failed to fetch watermark: {e}\", table=table_name)\n        return \"1900-01-01 00:00:00\"\n\ndef extract_and_save_to_landing(table, load_type, watermark_col):\n    try:\n        last_watermark = get_latest_watermark(table) if load_type.lower() == \"incremental\" else None\n        log_event(\"INFO\", f\"Latest watermark for {table}: {last_watermark}\", table=table)\n\n        query = f\"(SELECT * FROM {table}) AS t\" if load_type.lower() == \"full\" else \\\n                f\"(SELECT * FROM {table} WHERE {watermark_col} > '{last_watermark}') AS t\"\n\n        df = (spark.read.format(\"jdbc\")\n              .option(\"url\", MYSQL_CONFIG[\"url\"])\n              .option(\"user\", MYSQL_CONFIG[\"user\"])\n              .option(\"password\", MYSQL_CONFIG[\"password\"])\n              .option(\"driver\", MYSQL_CONFIG[\"driver\"])\n              .option(\"dbtable\", query)\n              .load())\n\n        count = df.count()\n        log_event(\"SUCCESS\", f\"Extracted {count} rows from {table}\", table=table)\n\n        today = datetime.datetime.today().strftime('%d%m%Y')\n        json_path = f\"landing/{HOSPITAL_NAME}/{table}/{table}_{today}.json\"\n        json_data = df.toPandas().to_json(orient=\"records\", lines=True) if count > 0 else \"[]\"\n        storage_client.bucket(GCS_BUCKET).blob(json_path).upload_from_string(json_data, content_type=\"application/json\")\n        log_event(\"SUCCESS\", f\"Data written to GCS at {json_path}\", table=table)\n\n        audit_df = spark.createDataFrame([\n            (\"hospital_a_db\", table, load_type, count, datetime.datetime.now(), \"SUCCESS\")\n        ], [\"data_source\", \"tablename\", \"load_type\", \"record_count\", \"load_timestamp\", \"status\"])\n\n        audit_df.write.format(\"bigquery\") \\\n            .option(\"table\", BQ_AUDIT_TABLE) \\\n            .option(\"temporaryGcsBucket\", GCS_BUCKET) \\\n            .mode(\"append\") \\\n            .save()\n        log_event(\"SUCCESS\", f\"Audit logged for {table}\", table=table)\n\n    except Exception as e:\n        log_event(\"ERROR\", f\"Extraction failed for {table}: {e}\", table=table)\n\ndef read_config_file():\n    try:\n        df = spark.read.csv(CONFIG_FILE_PATH, header=True)\n        log_event(\"INFO\", \"Config file read from GCS\")\n        return df\n    except Exception as e:\n        log_event(\"ERROR\", f\"Failed to read config: {e}\")\n        return None\n\n# Execution\nconfig_df = read_config_file()\nif config_df:\n    for row in config_df.collect():\n        # Use attribute access for Spark Rows\n        if row.is_active == '1' and row.datasource == \"hospital_a_db\":\n            # Unpack with attribute access\n            _, _, table, load_type, watermark_col, _, _ = row\n            move_existing_files_to_archive(table)\n            extract_and_save_to_landing(table, load_type, watermark_col)\n\n# Final logs\nsave_logs_to_gcs()\nsave_logs_to_bigquery()\n\n# Gracefully stop Spark only at the very end.\ntry:\n    spark.stop()\nexcept Exception as e:\n    print(f\"Warning: Exception while stopping Spark - {e}\")\n"}, {"cell_type": "code", "execution_count": null, "id": "39fcd154-cd4d-45df-a76d-85eaac58acca", "metadata": {}, "outputs": [], "source": "# Challanges :- If the table do not exists ?\n# sometimes connections to the db fails due to tech glitch , change in configs I failed beacuse of the authorized networks\n# Spark Session is killed silently\n# used gs:// bymistake             .option(\"temporaryGcsBucket\", GCS_BUCKET) \\\n\n#Logs generated \n\n\n[2025-08-04T14:39:56.948102] INFO - \u2705 Successfully read the config file\n                                                                                \n[2025-08-04T14:40:00.411421] INFO - No existing files for table encounters\n[2025-08-04T14:40:01.400284] INFO - Latest watermark for encounters: 1900-01-01 00:00:00\n[2025-08-04T14:40:02.261349] SUCCESS - \u2705 Successfully extracted data from encounters\n                                                                                \n[2025-08-04T14:40:05.597426] SUCCESS - \u2705 JSON file successfully written to gs://healthcare-bucket-192/landing/hospital-a/encounters/encounters_04082025.json\n                                                                                \n[2025-08-04T14:40:20.730979] SUCCESS - \u2705 Audit log updated for encounters\n[2025-08-04T14:40:20.758998] INFO - No existing files for table patients\n[2025-08-04T14:40:21.753406] INFO - Latest watermark for patients: 1900-01-01 00:00:00\n[2025-08-04T14:40:22.008675] SUCCESS - \u2705 Successfully extracted data from patients\n[2025-08-04T14:40:23.162369] SUCCESS - \u2705 JSON file successfully written to gs://healthcare-bucket-192/landing/hospital-a/patients/patients_04082025.json\n                                                                                \n[2025-08-04T14:40:35.353333] SUCCESS - \u2705 Audit log updated for patients\n[2025-08-04T14:40:35.385913] INFO - No existing files for table transactions\n[2025-08-04T14:40:36.515180] INFO - Latest watermark for transactions: 1900-01-01 00:00:00\n[2025-08-04T14:40:36.781461] SUCCESS - \u2705 Successfully extracted data from transactions\n                                                                                \n[2025-08-04T14:40:39.571988] SUCCESS - \u2705 JSON file successfully written to gs://healthcare-bucket-192/landing/hospital-a/transactions/transactions_04082025.json\n                                                                                \n[2025-08-04T14:40:47.979005] SUCCESS - \u2705 Audit log updated for transactions\n[2025-08-04T14:40:48.002546] INFO - No existing files for table providers\n[2025-08-04T14:40:48.002598] INFO - Latest watermark for providers: None\n[2025-08-04T14:40:48.249196] SUCCESS - \u2705 Successfully extracted data from providers\n[2025-08-04T14:40:48.808063] SUCCESS - \u2705 JSON file successfully written to gs://healthcare-bucket-192/landing/hospital-a/providers/providers_04082025.json\n                                                                                \n[2025-08-04T14:40:57.795551] SUCCESS - \u2705 Audit log updated for providers\n[2025-08-04T14:40:57.817477] INFO - No existing files for table departments\n[2025-08-04T14:40:57.817525] INFO - Latest watermark for departments: None\n[2025-08-04T14:40:58.062150] SUCCESS - \u2705 Successfully extracted data from departments\n[2025-08-04T14:40:58.584539] SUCCESS - \u2705 JSON file successfully written to gs://healthcare-bucket-192/landing/hospital-a/departments/departments_04082025.json\n                                                                                \n[2025-08-04T14:41:07.508641] SUCCESS - \u2705 Audit log updated for departments\n\u2705 Logs successfully saved to GCS at gs://healthcare-bucket-192/temp/pipeline_logs/pipeline_log_20250804144107.json\n                                                                                \n\u2705 Logs stored in BigQuery for future analysis\n\n\n\n\n# rerun logs \n\n\n[2025-08-04T15:04:01.825755] INFO - Config file read from GCS\n[2025-08-04T15:04:03.130861] INFO - Moved landing/hospital-a/encounters/encounters_04082025.json to landing/hospital-a/archive/encounters/2025/08/04/encounters_04082025.json\n[2025-08-04T15:04:04.166542] INFO - Latest watermark for encounters: 2025-08-04 14:47:13.904624+00:00\n                                                                                \n[2025-08-04T15:04:07.034496] SUCCESS - Extracted 0 rows from encounters\n[2025-08-04T15:04:07.190495] SUCCESS - Data written to GCS at landing/hospital-a/encounters/encounters_04082025.json\n                                                                                \n[2025-08-04T15:04:25.396609] SUCCESS - Audit logged for encounters\n[2025-08-04T15:04:26.616070] INFO - Latest watermark for patients: 2025-08-04 14:47:31.606692+00:00\n[2025-08-04T15:04:27.341033] SUCCESS - Extracted 0 rows from patients\n[2025-08-04T15:04:27.496143] SUCCESS - Data written to GCS at landing/hospital-a/patients/patients_04082025.json\n                                                                                \n[2025-08-04T15:04:39.803861] SUCCESS - Audit logged for patients\n[2025-08-04T15:04:41.057745] INFO - Latest watermark for transactions: 2025-08-04 14:40:40.429157+00:00\n                                                                                \n[2025-08-04T15:04:42.777374] SUCCESS - Extracted 0 rows from transactions\n[2025-08-04T15:04:42.942221] SUCCESS - Data written to GCS at landing/hospital-a/transactions/transactions_04082025.json\n                                                                                \n[2025-08-04T15:04:49.489982] SUCCESS - Audit logged for transactions\n[2025-08-04T15:04:49.513605] INFO - Latest watermark for providers: None\n[2025-08-04T15:04:50.344639] SUCCESS - Extracted 26 rows from providers\n[2025-08-04T15:04:51.025068] SUCCESS - Data written to GCS at landing/hospital-a/providers/providers_04082025.json\n                                                                                \n[2025-08-04T15:04:59.714515] SUCCESS - Audit logged for providers\n[2025-08-04T15:04:59.741160] INFO - Latest watermark for departments: None\n[2025-08-04T15:05:00.389652] SUCCESS - Extracted 21 rows from departments\n[2025-08-04T15:05:00.967031] SUCCESS - Data written to GCS at landing/hospital-a/departments/departments_04082025.json\n                                                                                \n[2025-08-04T15:05:07.460345] SUCCESS - Audit logged for departments\n\u2705 Logs saved to GCS: gs://healthcare-bucket-192/temp/pipeline_logs/pipeline_log_20250804150507.json\n                                                                                \n\u2705 Logs written to BigQuery\n"}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.15"}}, "nbformat": 4, "nbformat_minor": 5}